---
title: "Practica2"
author: "Sebastian Cueva, Pol Gracia"
date: "11/12/2022"
output:
  html_notebook: default
  html_document: default
---

# 0. Imports
A continuación se expone el código y comentarios resultados de la realización de la práctica 2.
#### Importar librerias

```{r warning=FALSE}
library(tidyverse)
library(tidyr)
library(dplyr)
library(knitr)
library(ggplot2)
library(stringr)
library(reshape)
library(minerva)
library(heatmaply)
library(kableExtra)
library(factoextra)
library(ggbiplot)
library(randomForest)
library(ROCR)
library(vcd)
library(ggmosaic)
library(cowplot)
library(caret)
library(e1071)
library(caTools)
library(class)
library(AUC)
library(ggcorrplot)
```

#### Importar datos

Aunque se nos entrega el fichero de train entero y podriamos obtener la variable respuesta, se trataran cómo si de un caso real se tratara, y todo el EDA y el training se usara solo el p2_train. El p2_test se usara únicamente para validar los resultados al final de todo de la practica.

```{r}
p2_train <- read.csv("D:/Master big data/Estadistica/Practica 1/P2-BANK-STUDENTS (1)/P2-BANK-STUDENTS/p2_train.csv", head = TRUE, sep=";", stringsAsFactors=TRUE)

p2_test <- read.csv("D:/Master big data/Estadistica/Practica 1/P2-BANK-STUDENTS (1)/P2-BANK-STUDENTS/p2_test.csv", sep=";", head = TRUE, stringsAsFactors=TRUE)
```


# 1. Preprocesado de los datos

En este apartado se va hacer el análisi exploratorio de los datos.


```{r}
head(p2_train)
```



Summary de los datos


```{r}
summary(p2_train) 
```

Se elimina la variable pdays debido a que no a porta informacion porque solo tiene digitos 999

```{r}
p2_train <- p2_train %>% select(-pdays)
```


### Para los datos : 

#### 1.0 Nan handling

Se puede apreciar que no encontramos ningún nan en las columnas del dataset, haciendo que no tengamos que tratar con ellos.

```{r}
p2_train %>% group_by() %>% summarise_all(funs(sum(is.na(.))))
```

#### 1.1 Duplicates handling

Se eliminan las filas duplicadas del dataset.

```{r}
p2_train <- p2_train %>%
                distinct()
p2_train
```

Eliminamos la variable id del dataset ya que es el indice, y no aporta información.

```{r}
p2_train_fin <- p2_train
p2_train <- p2_train %>% select(-id)
```
#### 1.2. Separar datos entre numericos y categoricos


Se visualiza si la estructura de las variables
```{r}
str(p2_train)

```
se visualiza de la siguiente manera para separar las numericas de las categoricas 

```{r}
sapply(p2_train, class) 
```
Se visualiza el numero de columna que se encuentra cada variable factorial

```{r}
 which(sapply(p2_train, is.factor))
```

Se crea un vector con las columnas que son factoriales 

```{r}
var.cat <- which(sapply(p2_train,class)=="factor" & names(p2_train)!="y")
```
Se visualiza las variables factoriales con relacion a la variable Y
```{r}

for(vc in var.cat)  mosaicplot(p2_train[,vc]~p2_train$y,main=names(p2_train)[vc],col=2:3,las=1)
```
En estos plot representan las variables categoricas del data frame con relacion a la variable "y", para visualizar su proporcion.


#### 2.0. Hacer boxplots de los campos y mirar outliers en los datos

(Sobre variables numericas)

```{r}
meltPred <- p2_train %>% select(where(is.numeric)) %>% melt()
meltPred %>%
 ggplot(aes(factor(variable), value)) +
   geom_violin(width=1, color = "gray", alpha = 0.2, fill = 'green' ) +
    geom_boxplot(width=0.3, color="black", fill='blue', alpha=0.3, outlier.colour="red", outlier.shape=8,
             outlier.size=1, notch=TRUE) + facet_wrap(~variable, scale="free")



```

Estos gráficos representan un boxplot y un violinplot sobre todas las variables numericas del dataset. Podemos apreciar:

- La columna age se ditribuye entre el 17 y el 98, con una media situada en los 39.98.  Encontramos numersos outliers cuando el valor es mayor de 70.

- La columna campaign se ditribuye entre el 1 y el 31, con una media situada en los 2.559. Encontramos numersos outliers cuando el valor es mayor de 7.

- La columna previous se ditribuye entre el 0 y el 7, con una media situada en los 0.16. Encontramos numersos outliers cuando el valor es mayor de 1.

- La columna emp.var.rate se distribuye entre el -3.4 y el 1.4 con una media alrededor de los 0.068. No encontramos otuliers.

- La columna cons.price.idx se distribuye entre el 92 y el 94 con una media alrededor de los 93. No encontramos otuliers.

- La columna cons.conf.idx se distribuye entre el -50 y el -26 con una media alrededor de los -40. Encontramos otuliers cuando el valor es mayor a -30.

- La columna euriborn3m se distribuye entre el 0.6 y el 5 con una media alrededor de los 3.6. No encontramos otuliers.

- La columna nr.employed se distribuye entre el 4964 y el 5228 con una media alrededor de los 5166. No encontramos otuliers.


#### 2.1 Matriz de correlaciones de pearson de las variables numericas

```{r}
corrp <- p2_train %>% select(where(is.numeric)) %>%  cor(method = 'pearson')
corrp %>% ggcorrplot(hc.order = TRUE, type = 'lower', lab=TRUE,
                      outline.col = "white",
                       ggtheme = ggplot2::theme_gray,
                       colors = c("#6D9EC1", "white", "#E46726")
                      )

```
mejora en la prediccion.
Con la variable nr.employed, estan directamente relacionadas las columnas emp.var.rate, euribor3m, y previous y la columna euribor3m esta indirectamente realcionada.


#### 2.3 PCA 

Realizamos un PCA sobre los datos para extraer los componentes principales y estudiarlos.

```{r}
pca <- p2_train %>% select(where(is.numeric)) %>% sample_n(200) %>%
  prcomp(scale. = TRUE, center = TRUE) #Se debe hacer un sample para posteriormente poder apreciar graficamente la distribución PCA.
summary(pca)
```

```{r}
pca %>% 
  ggbiplot::ggbiplot(scale = 1,ellipse = T)

```

Gràfico que representa la ponderación de las variables utilizadas para el PCA.


#### 3 Grafica categorica

Para graficarlo se realiza un one hot coding del data frame para apreciar de forma adecuado la categoria "y", ademas el codigicado de los datos categoricos a numericos con el one hot coding nos permite entrenar modelos de clasificacion que solo toman variables numericas. Hay que tener en cuenta que esta misma transformacion se debera aplicar sobre los datos de testing.

```{r}
onehot <- dummyVars(" ~ .", data=p2_train)
onehotdata <- data.frame(predict(onehot, newdata = p2_train)) 

onehotdata

```


Partiendo de la base que la variable target es categorica, se aprecia una gran cantidad de y con no a comparacion de yes.


```{r}
ggplot(data = 
    onehotdata %>% 
    select(y.no, y.yes) %>% 
    mutate(y = ifelse(y.no == 1, "No",
        ifelse(y.yes == 1, "Yes", "NONE"))),
    aes(x = y, fill = y)
) + 
    geom_bar() 

```
 Se aprecia que nos encontramos ante un caso de dataset no balanceado aunque las diferencias de proporcion no son lo suficientemente grandes para causar demasiado overfiting en nuestros modelos y deberian poder generalizar bien, por este motivo, ademas de que no tenemos muchos datos, no realizaremos tecnicas de oversampling o undersampling. 
 
 
## 4. Prediccion
#### 4.1 Normalización y preparación de los datos

Hacemos un escalado sobre los datos para normalizar. 

```{r}
onehotdata <- onehotdata %>% mutate(across(where(is.numeric), scale))
```
La variable target debe quedar fuera del one hot coding
```{r}
onehotdata <- onehotdata %>% select(-y.no,-y.yes)
onehotdata <- onehotdata %>% mutate(y=as.factor(ifelse(p2_train$y== "yes", 1, 0)))
onehotdata
```
Se agrega la columna "y" representando yes con 1 y viceversa.

#### 4.2 Separar entre train y test
Aunque se nos dan dos data sets, el data set de test no tiene la variable ground truth y es necesario saber como va a rendir nuestro modelo con datos que nohaya visto anterior mente por este motivo vamos a separar el data set en train y test.

```{r}
p <- 0.8                                   
n <- nrow(onehotdata)                               
set.seed(123456)
train.sel <- sample(c(FALSE,TRUE),n,rep=TRUE,prob=c(1-p,p))
train <- onehotdata[train.sel,]
test <- onehotdata[!train.sel,]

train

```




#### 4.3 KNN 
```{r}
classifier_knn <- knn(train = train,
test = test,
cl = train$y,
k = 20)

length(classifier_knn)

```

Rendimiento sobre el test:
```{r}
# Confusiin Matrix
cm <- table(test$y, classifier_knn)
cm

# Accuracy
misClassError <- mean(classifier_knn != test$y)
print(paste('Accuracy =', 1-misClassError))

```
Con el modelo del KNN con la k=20 obtenemos accuracy sobre el test del 90%. Ademas viendo la confusion matrix se aprecia como nuestro modelo no esta overfited ya que vemos que la clase minoritaria tiene numerosas asignaciones correctas.

#### 4.4 SVM

```{r}
mod_svm = svm(y ~ ., data = train, kernel = "linear", cost = 10, scale = FALSE)
print(mod_svm)
```
```{r}
y_pred = predict(mod_svm, newdata = select(test,-y))

```
Rendimiento sobre el test:
```{r}
# Confusiin Matrix
cm <- table(test$y, y_pred)
cm

# Accuracy
misClassError <- mean(y_pred != test$y)
print(paste('Accuracy =', 1-misClassError))

```
Con el modelo del SVM con la cost=10 obtenemos accuracy sobre el test del 88%. Ademas viendo la confusion matrix se aprecia como nuestro modelo no esta overfited ya que vemos que la clase minoritaria tiene numerosas asignaciones correctas.

#### 4.5 Random Forest
```{r}
mod_rf <- randomForest(y ~ .,
data = train,
importance = TRUE,
proximity = TRUE)

mod_rf
```
```{r}
y_pred = predict(mod_rf, newdata = select(test,-y))

```
Rendimiento sobre el test:
```{r}
# Confusiin Matrix
cm <- table(test$y, y_pred)
cm

# Accuracy
misClassError <- mean(y_pred != test$y)
print(paste('Accuracy =', 1-misClassError))

```
Con el modelo del Random Forest de clasificacion obtenemos accuracy sobre el test del 95%. Ademas viendo la confusion matrix se aprecia como nuestro modelo no esta overfited ya que vemos que la clase minoritaria tiene numerosas asignaciones correctas.

```{r}
mseDF <- data.frame(id = p2_train_fin[!train.sel,]$id, gt = y_pred)
mseDF

```
Exportar a un fichero p2.txt de texto con la probabilidad predicha con la columna id y su probabilidad 
```{r}
write.table(x = mseDF, file = "p2.txt", sep = ",", 
            row.names = FALSE, col.names = TRUE)
```

```{r}
boxplot(y_pred~p2_train_fin[!train.sel,]$y)             # Como son estas probabilidades en ambos grupos de respuesta
roc.curve <- roc(y_pred,p2_train_fin[!train.sel,]$y)    # Calculo de la curva ROC
plot(roc.curve)                # Dibujo de la curva ROC
AUC::auc(roc.curve) 
```

## 3. Conclusiones

El algoritmo de random forest es el que mejor predice la probabilidad del cliente que se le realiza la llamada acepte el producto que se le ofrece, con un accurancy del 95%. Podemos ver analizando los resultados que el modelo no tiene mucho overfitting y generaliza bien, esto es asi en parte al haber creado un arbol no demasiado grande, evitando así la caída de valores en hojas. 

Cómo algoritmos de clasificacion se podrian intentar también el xgboost o el catboost pero perderiamos entendimiento de lo que esta haciendo el modelo, asi que se ha obviado para este trabajo.
