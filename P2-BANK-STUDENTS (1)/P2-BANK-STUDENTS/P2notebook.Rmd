---
title: "Practica2"
author: "Sebastian Cueva, Pol Gracia"
date: "11/12/2022"
output:
  html_notebook: default
  html_document: default
---

# 0. Imports
A continuación se expone el código y comentarios resultados de la realización de la práctica 2.
#### Importar librerias

```{r}
library(tidyverse)
library(tidyr)
library(dplyr)
library(knitr)
library(ggplot2)
library(stringr)
library(reshape)
library(minerva)
library(heatmaply)
library(kableExtra)
library(factoextra)
library(ggbiplot)
library(randomForest)
library(ROCR)
library(vcd)
library(ggmosaic)
library(cowplot)
```

#### Importar datos

Aunque se nos entrega el fichero de train entero y podriamos obtener la variable respuesta, se trataran cómo si de un caso real se tratara, y todo el EDA y el training se usara solo el p2_train. El p2_test se usara únicamente para validar los resultados al final de todo de la practica.

```{r}
p2_train <- read.csv("D:/Master big data/Estadistica/Practica 1/P2-BANK-STUDENTS (1)/P2-BANK-STUDENTS/p2_train.csv", head = TRUE, sep=";", stringsAsFactors=TRUE)

p2_test <- read.csv("D:/Master big data/Estadistica/Practica 1/P2-BANK-STUDENTS (1)/P2-BANK-STUDENTS/p2_test.csv", sep=";", head = TRUE, stringsAsFactors=TRUE)
```


# 1. Preprocesado de los datos

En este apartado se va hacer el análisi exploratorio de los datos.


```{r}
head(p2_train)
```

Eliminamos la variable id del dataset ya que es el indice, y no aporta información.

```{r}
p2_train <- p2_train %>% select(-id)
```

Summary de los datos


```{r}
summary(p2_train) 
```

Se elimina la variable pdays debido a que no a porta informacion porque solo tiene digitos 999

```{r}
p2_train <- p2_train %>% select(-pdays)
```


### Para los datos : 

#### 1.0 Nan handling

Se puede apreciar que no encontramos ningún nan en las columnas del dataset, haciendo que no tengamos que tratar con ellos.

```{r}
p2_train %>% group_by() %>% summarise_all(funs(sum(is.na(.))))
```

#### 1.1 Duplicates handling

Se eliminan las filas duplicadas del dataset.

```{r}
p2_train <- p2_train %>%
                distinct()
p2_train
```


#### 1.2. Separar datos entre numericos y categoricos


Se visualiza si la estructura de las variables
```{r}
str(p2_train)

```
se visualiza de la siguiente manera para separar las numericas de las categoricas 

```{r}
sapply(p2_train, class) 
```
Se visualiza el numero de columna que se encuentra cada variable factorial

```{r}
 which(sapply(p2_train, is.factor))
```

Se crea un vector con las columnas que son factoriales 

```{r}
var.cat <- which(sapply(p2_train,class)=="factor" & names(p2_train)!="y")
```
Se visualiza las variables factoriales con relacion a la variable Y
```{r}

for(vc in var.cat)  mosaicplot(p2_train[,vc]~p2_train$y,main=names(p2_train)[vc],col=2:3,las=1)
```

opcion 2 de grafico 

```{r}
ggplot(p2_train, aes(y,  fill=job)) +      #1
  geom_bar()+                                          #2
  
  labs(x= "Y",  y="Frecuencias", fill="Job") +  #3 
  
  ylim(c(0,30000))  +                  #4   
  #xlim(c(0,300)) +                  #4
  
  ggtitle("Diagrama de barras") +    #5
  #coord_flip() +                    #6
  #theme_bw() +                      #7
  theme_bw(base_size = 12) 
```

#### 2.0. Hacer boxplots de los campos y mirar outliers en los datos

(Sobre variables numericas)

```{r}
meltPred <- p2_train %>% select(where(is.numeric)) %>% melt()
meltPred %>%
 ggplot(aes(factor(variable), value)) +
   geom_violin(width=1, color = "gray", alpha = 0.2, fill = 'green' ) +
    geom_boxplot(width=0.3, color="black", fill='blue', alpha=0.3, outlier.colour="red", outlier.shape=8,
             outlier.size=1, notch=TRUE) + facet_wrap(~variable, scale="free")
```

Estos gráficos representan un boxplot y un violinplot sobre todas las variables numericas del dataset. Podemos apreciar:

- La columna age se ditribuye entre el 17 y el 98, con una media situada en los 39.98.  Encontramos numersos outliers cuando el valor es mayor de 70.

- La columna campaign se ditribuye entre el 1 y el 31, con una media situada en los 2.559. Encontramos numersos outliers cuando el valor es mayor de 7.

- La columna previous se ditribuye entre el 0 y el 7, con una media situada en los 0.16. Encontramos numersos outliers cuando el valor es mayor de 1.

- La columna emp.var.rate se distribuye entre el -3.4 y el 1.4 con una media alrededor de los 0.068. No encontramos otuliers.

- La columna cons.price.idx se distribuye entre el 92 y el 94 con una media alrededor de los 93. No encontramos otuliers.

- La columna cons.conf.idx se distribuye entre el -50 y el -26 con una media alrededor de los -40. Encontramos otuliers cuando el valor es mayor a -30.

- La columna euriborn3m se distribuye entre el 0.6 y el 5 con una media alrededor de los 3.6. No encontramos otuliers.

- La columna nr.employed se distribuye entre el 4964 y el 5228 con una media alrededor de los 5166. No encontramos otuliers.


#### 2.1 Matriz de correlaciones de pearson de las variables numericas

```{r}
corrp <- p2_train %>% select(where(is.numeric)) %>%  cor(method = 'pearson')
corrp %>% ggcorrplot(hc.order = TRUE, type = 'lower', lab=TRUE,
                      outline.col = "white",
                       ggtheme = ggplot2::theme_gray,
                       colors = c("#6D9EC1", "white", "#E46726")
                      )

```
mejora en la prediccion.
Con la variable nr.employed, estan directamente relacionadas las columnas emp.var.rate, euribor3m, y previous y la columna euribor3m esta indirectamente realcionada.


#### 2.3 PCA 

Realizamos un PCA sobre los datos para extraer los componentes principales y estudiarlos.

```{r}
pca <- p2_train %>% select(where(is.numeric)) %>% sample_n(200) %>%
  prcomp(scale. = TRUE, center = TRUE) #Se debe hacer un sample para posteriormente poder apreciar graficamente la distribución PCA.
summary(pca)
```

```{r}
pca %>% 
  ggbiplot::ggbiplot(scale = 1,ellipse = T)

```

Gràfico que representa la ponderación de las variables utilizadas para el PCA.


#### 3 Grafica categorica

Para graficarlo se realiza un one hot coding del data frame para apreciar de forma adecuado la categoria "y"

```{r}
dummy <- dummyVars(" ~ .", data=p2_train)
newdata <- data.frame(predict(dummy, newdata = p2_train)) 

newdata
```


Partiendo de la base que la variable target es categorica, se aprecia una gran cantidad de y con no a comparacion de yes.


```{r}
ggplot(data = 
    newdata %>% 
    select(y.no, y.yes) %>% 
    mutate(y = ifelse(y.no == 1, "No",
        ifelse(y.yes == 1, "Yes", "NONE"))),
    aes(x = y, fill = y)
) + 
    geom_bar() 

```
  
 Para reducir las categorias y crear nuevas columnas vamos a clonar el dateframe con nombre prediction
 
 
 





